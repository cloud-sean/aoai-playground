{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n",
      "Exiting: Cleaning up .chroma directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a client for the chroma vector store locally\n",
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_client.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = openai.api_type = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = openai.api_version = \"2022-12-01\"\n",
    "\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"] = \"ENTER ENDPOINT HERE\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"] = \"ENTER KEY HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that will be used to embed documents when they are entered into the vector store\n",
    "from chromadb.utils import embedding_functions\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "                model_name=\"text-embedding-ada-002\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to use the directory loader which will leverage a local version of Unstructured-io / this can be replaced with any other loader or with Azure Form Recognizer\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader('data/', glob=\"**/*.pdf\")\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all the documents that were loaded\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split every document into chunks \n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:51<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "#generate embeddings for each chunk\n",
    "import time, tqdm\n",
    "embeddings = []\n",
    "\n",
    "for text in tqdm.tqdm(texts):\n",
    "    try:\n",
    "        response = openai.Embedding.create(\n",
    "            input=text.page_content,\n",
    "            engine=\"text-embedding-ada-002\")\n",
    "        emb = response['data'][0]['embedding']\n",
    "        embeddings.append(emb)\n",
    "    except Exception as e:\n",
    "        time.sleep(8)\n",
    "        response = openai.Embedding.create(\n",
    "            input=text.page_content,\n",
    "            engine=\"text-embedding-ada-002\")\n",
    "        emb = response['data'][0]['embedding']\n",
    "        embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# initialize the vector store and create a openai embedding function\n",
    "azure_embeddings = OpenAIEmbeddings(document_model_name=\"text-embedding-ada-002\",query_model_name=\"text-embedding-ada-002\")\n",
    "vectorstore = Chroma(\"my_collection\", embedding_function=azure_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the documents to the vector store\n",
    "vectorstore._collection.add(\n",
    "    ids= [f\"doc_{i}\" for i in range(len(texts))],\n",
    "    documents=[texts[i].page_content for i in range(len(texts))],\n",
    "    embeddings=embeddings,\n",
    "    metadatas=[text.metadata for text in texts]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create custom templates pass them in later\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. If there are multiple answers, describe them all.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    ":\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import VectorDBQAWithSourcesChain\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "#initialize our chain\n",
    "# THIS IS WHERE YOU CAN PASS YOUR PROMPT TEMPLATE !\n",
    "chain = VectorDBQAWithSourcesChain.from_chain_type(llm=AzureOpenAI(deployment_name=\"davinci003\", model_name=\"text-davinci-003\"), chain_type=\"stuff\", vectorstore=vectorstore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': ' The rate of infections for clarinex as adverse events was 4.1% for CLARINEX Tablets 5 mg and 2.0% for placebo.\\n', 'sources': 'data/c_clarinex_clarinex_pi.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# test the chain\n",
    "answer = chain({\"question\": \"What was the rate of infections for clarinex as advese events?\"}, return_only_outputs=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_answer(question):\n",
    "    answer = chain({'question': question}, return_only_outputs=True)\n",
    "    answer = f\"\"\"{answer['answer']}\\n\\n source: {answer['sources']}\"\"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small interface for Q/A against document set.\n",
    "import gradio as gr \n",
    "with gr.Blocks() as demo:\n",
    "    text = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
    "    answerbox = gr.Textbox(show_label=False, placeholder=\"Answer\").style(container=False)\n",
    "    text.submit(return_answer, inputs=[text], outputs=[answerbox])\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7452631343f8c3c6af794cacededb45b4dc4c4983caaec0c13d44a57fb09d98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
